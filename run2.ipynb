{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import conllu\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from conllu import parse, parse_incr, parse_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "26902\n[{'form': '2012年', 'upos': 'NOUN'}, {'form': '12月', 'upos': 'NOUN'}, {'form': '我', 'upos': 'PRON'}, {'form': '在', 'upos': 'ADP'}, {'form': '韩国', 'upos': 'PROPN'}, {'form': '留学', 'upos': 'VERB'}, {'form': '的', 'upos': 'PART'}, {'form': '时候', 'upos': 'NOUN'}, {'form': '，', 'upos': 'PUNCT'}, {'form': '有', 'upos': 'VERB'}, {'form': '一', 'upos': 'NUM'}, {'form': '天', 'upos': 'NOUN'}, {'form': '接', 'upos': 'VERB'}, {'form': '到', 'upos': 'VERB'}, {'form': '一', 'upos': 'NUM'}, {'form': '个', 'upos': 'NOUN'}, {'form': '通知', 'upos': 'NOUN'}, {'form': '。', 'upos': 'PUNCT'}]\n"
     ]
    }
   ],
   "source": [
    "corpus_file = json.load(open('../corpus.json','r', encoding=\"utf-8\")) \n",
    "print(len(corpus_file))\n",
    "print(corpus_file[0])"
   ]
  },
  {
   "source": [
    "# 1. 概率方法\n",
    "## step1  统计数据"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 26902/26902 [00:01<00:00, 15837.05it/s]\n",
      "100%|██████████| 26902/26902 [00:01<00:00, 16394.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# 频率方法\n",
    "frequency_bigram_set = {}                  # 双层字典\n",
    "frequency_bigram_set2 = {}                 # 单层字典\n",
    "for sentence in tqdm(corpus_file):\n",
    "    for word_index in range(len(sentence) - 1):\n",
    "        if sentence[word_index]['upos'] == 'PUNCT' or sentence[word_index + 1]['upos'] == 'PUNCT' or (sentence[word_index]['form'] in ['。', '，', '“', '”','——']) or (sentence[word_index + 1]['form'] in ['。', '，', '“', '”','——']):\n",
    "            continue\n",
    "\n",
    "        frequency_bigram_set2[f\"{sentence[word_index]['form']}&{sentence[word_index]['upos']}&{sentence[word_index + 1]['form']}&{sentence[word_index + 1]['upos']}\"] = 0\n",
    "        try:\n",
    "            frequency_bigram_set[f\"{sentence[word_index]['form']}&{sentence[word_index]['upos']}\"][f\"{sentence[word_index + 1]['form']}&{sentence[word_index + 1]['upos']}\"] = 0\n",
    "        except:\n",
    "            frequency_bigram_set[f\"{sentence[word_index]['form']}&{sentence[word_index]['upos']}\"] = {}\n",
    "            frequency_bigram_set[f\"{sentence[word_index]['form']}&{sentence[word_index]['upos']}\"][f\"{sentence[word_index + 1]['form']}&{sentence[word_index + 1]['upos']}\"] = 0\n",
    "\n",
    "for sentence in tqdm(corpus_file):\n",
    "    for word_index in range(len(sentence) - 1):\n",
    "        if sentence[word_index]['upos'] == 'PUNCT' or sentence[word_index + 1]['upos'] == 'PUNCT' or (sentence[word_index]['form'] in ['。', '，', '“', '”','——']) or (sentence[word_index + 1]['form'] in ['。', '，', '“', '”','——']):\n",
    "            continue\n",
    "        \n",
    "        frequency_bigram_set2[f\"{sentence[word_index]['form']}&{sentence[word_index]['upos']}&{sentence[word_index + 1]['form']}&{sentence[word_index + 1]['upos']}\"] += 1\n",
    "        frequency_bigram_set[f\"{sentence[word_index]['form']}&{sentence[word_index]['upos']}\"][f\"{sentence[word_index + 1]['form']}&{sentence[word_index + 1]['upos']}\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据保存\n",
    "json.dump(frequency_bigram_set, open('../output/概率方法/frequency_bigram_set.json','w', encoding =\"utf-8\"), ensure_ascii = False, indent = 2)\n",
    "json.dump(frequency_bigram_set2, open('../output/概率方法/frequency_bigram_set2.json','w', encoding =\"utf-8\"), ensure_ascii = False, indent = 2)"
   ]
  },
  {
   "source": [
    "## step2  分析结果"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 频率方法 排序\n",
    "frequency_bigram_set = json.load(open('../output/概率方法/frequency_bigram_set.json','r', encoding=\"utf-8\")) \n",
    "frequency_bigram_set2 = json.load(open('../output/概率方法/frequency_bigram_set2.json','r', encoding=\"utf-8\")) \n",
    "frequency_bigram_set2_sorted = sorted(frequency_bigram_set2.items(), key = lambda kv:(kv[1], kv[0]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "===================== frequency By Tag Pattern: (VERB NOUN) =====================\n1: ('附&VERB&图片&NOUN', 293)\n2: ('令&VERB&人&NOUN', 144)\n3: ('反&VERB&腐败&NOUN', 139)\n4: ('是&VERB&我国&NOUN', 93)\n5: ('高举&VERB&邓小平理论&NOUN', 83)\n6: ('为&VERB&核心&NOUN', 83)\n7: ('跨&VERB&世纪&NOUN', 78)\n8: ('让&VERB&人&NOUN', 73)\n9: ('是&VERB&个&NOUN', 70)\n10: ('有&VERB&可能&NOUN', 69)\n===================== frequency By Tag Pattern: (None None) =====================\n1: ('的&PART&一&NUM', 1047)\n2: ('新&ADJ&的&PART', 768)\n3: ('这&PRON&一&NUM', 645)\n4: ('一&NUM&种&NOUN', 626)\n5: ('这&PRON&是&VERB', 584)\n6: ('了&PART&一&NUM', 577)\n7: ('的&PART&发展&NOUN', 544)\n8: ('一&NUM&年&NOUN', 544)\n9: ('中&ADP&的&PART', 522)\n10: ('就&ADV&是&VERB', 520)\n===================== frequency By Word0: (高举&VERB None) =====================\n1: (高举&VERB&邓小平理论&NOUN, 83)\n2: (高举&VERB&旗帜&NOUN, 4)\n3: (高举&VERB&毛泽东思想&NOUN, 3)\n4: (高举&VERB&邓&PROPN, 2)\n5: (高举&VERB&伟大&ADJ, 2)\n6: (高举&VERB&起&VERB, 1)\n7: (高举&VERB&胳膊&NOUN, 1)\n8: (高举&VERB&社会主义&NOUN, 1)\n9: (高举&VERB&爱国主义&NOUN, 1)\n10: (高举&VERB&政治&NOUN, 1)\n===================== frequency By Word0: (高举&VERB NOUN) =====================\n1: (高举&VERB&邓小平理论&NOUN, 83)\n2: (高举&VERB&旗帜&NOUN, 4)\n3: (高举&VERB&毛泽东思想&NOUN, 3)\n4: (高举&VERB&胳膊&NOUN, 1)\n5: (高举&VERB&社会主义&NOUN, 1)\n6: (高举&VERB&爱国主义&NOUN, 1)\n7: (高举&VERB&政治&NOUN, 1)\n"
     ]
    }
   ],
   "source": [
    "# 查询某个类别\n",
    "def frequencyByTagPattern(frequency_bigram_set2_sorted, tag_pattern, K = 10):\n",
    "    print(f'===================== frequency By Tag Pattern: ({tag_pattern[0]} {tag_pattern[1]}) =====================')\n",
    "    count = 0\n",
    "    for bigram in frequency_bigram_set2_sorted:\n",
    "        if count >= K:\n",
    "            break\n",
    "        pattern0 = bigram[0].split('&')[1]\n",
    "        pattern1 = bigram[0].split('&')[3]\n",
    "        if (not tag_pattern[0] == None) and (not tag_pattern[1] == None) and pattern0 == tag_pattern[0] and pattern1 == tag_pattern[1]:\n",
    "            count += 1\n",
    "            print(f'{count}: {bigram}')\n",
    "        elif (not tag_pattern[0] == None) and (tag_pattern[1] == None) and pattern0 == tag_pattern[0]:\n",
    "            count += 1\n",
    "            print(f'{count}: {bigram}')\n",
    "        elif (tag_pattern[0] == None) and (not tag_pattern[1] == None) and pattern1 == tag_pattern[1]:\n",
    "            count += 1\n",
    "            print(f'{count}: {bigram}')\n",
    "        elif (tag_pattern[0] == None) and (tag_pattern[1] == None):\n",
    "            count += 1\n",
    "            print(f'{count}: {bigram}')\n",
    "\n",
    "def frequencyByWord0(frequency_bigram_set, word0, tag_pattern0, tag_pattern1 = None, K = 10):\n",
    "    print(f'===================== frequency By Word0: ({word0}&{tag_pattern0} {tag_pattern1}) =====================')\n",
    "    sub_frequency_bigram_set = frequency_bigram_set[f'{word0}&{tag_pattern0}']\n",
    "    sub_frequency_bigram_set = sorted(sub_frequency_bigram_set.items(), key = lambda kv:(kv[1], kv[0]), reverse=True)\n",
    "    count = 0\n",
    "    for word1_pattern1 in sub_frequency_bigram_set:\n",
    "        if count >= K:\n",
    "            break\n",
    "        \n",
    "        pattern1 = word1_pattern1[0].split('&')[1]\n",
    "        if (not tag_pattern1 == None) and pattern1 == tag_pattern1:\n",
    "            count += 1\n",
    "            print(f'{count}: ({word0}&{tag_pattern0}&{word1_pattern1[0]}, {word1_pattern1[1]})')\n",
    "        elif tag_pattern1 == None:\n",
    "            count += 1\n",
    "            print(f'{count}: ({word0}&{tag_pattern0}&{word1_pattern1[0]}, {word1_pattern1[1]})')\n",
    "\n",
    "# 按照可能性大小得顺序列出十个搭配及相关分数\n",
    "tag_pattern = ['VERB', 'NOUN']\n",
    "frequencyByTagPattern(frequency_bigram_set2_sorted, tag_pattern)\n",
    "frequencyByTagPattern(frequency_bigram_set2_sorted, [None, None])\n",
    "\n",
    "frequencyByWord0(frequency_bigram_set, '高举', 'VERB', tag_pattern1 = None)\n",
    "frequencyByWord0(frequency_bigram_set, '高举', 'VERB', tag_pattern1 = 'NOUN')"
   ]
  },
  {
   "source": [
    "# 2. t-test 假设检验方法\n",
    "## step1  统计数据"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 26902/26902 [00:00<00:00, 42263.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# t-test 假设检验方法\n",
    "frequency_unigram_set = {}                  # 单层字典，统计每个词出现的个数\n",
    "for sentence in tqdm(corpus_file):\n",
    "    for word_index in range(len(sentence)):\n",
    "        if sentence[word_index]['upos'] == 'PUNCT' or sentence[word_index]['form'] in ['。', '，', '“', '”','——']:\n",
    "            continue\n",
    "        try:\n",
    "            frequency_unigram_set[f\"{sentence[word_index]['form']}&{sentence[word_index]['upos']}\"] += 1\n",
    "        except:\n",
    "            frequency_unigram_set[f\"{sentence[word_index]['form']}&{sentence[word_index]['upos']}\"] = 1\n",
    "json.dump(frequency_unigram_set, open('../output/t-test假设检验方法/frequency_unigram_set.json','w', encoding =\"utf-8\"), ensure_ascii = False, indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1087497\n"
     ]
    }
   ],
   "source": [
    "# t-test 假设检验方法\n",
    "frequency_unigram_set = json.load(open('../output/t-test假设检验方法/frequency_unigram_set.json','r', encoding=\"utf-8\")) \n",
    "frequency_bigram_set2 = json.load(open('../output/概率方法/frequency_bigram_set2.json','r', encoding=\"utf-8\")) \n",
    "N_unigram = 1087497             # 没有标点符号的 unigram\n",
    "N_bigram = 899680               # 没有标点符号的 bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 456721/456721 [00:00<00:00, 560511.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# 计算每个搭配的t\n",
    "t_set = {}\n",
    "\n",
    "for bigram in tqdm(frequency_bigram_set2):\n",
    "    word_pattern = bigram.split('&')\n",
    "    word0 = f'{word_pattern[0]}&{word_pattern[1]}'\n",
    "    word1 = f'{word_pattern[2]}&{word_pattern[3]}'\n",
    "    x_ = frequency_bigram_set2[bigram] / N_bigram\n",
    "    mu = (frequency_unigram_set[word0] / N_bigram) * (frequency_unigram_set[word1] / N_bigram)\n",
    "    t = (x_ - mu) / math.sqrt(x_ / N_bigram)\n",
    "\n",
    "    t_set[bigram] = t\n",
    "json.dump(t_set, open('../output/t-test假设检验方法/t_set.json','w', encoding =\"utf-8\"), ensure_ascii = False, indent = 2)"
   ]
  },
  {
   "source": [
    "## step2  分析结果"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 频率方法 排序\n",
    "frequency_unigram_set = json.load(open('../output/t-test假设检验方法/frequency_unigram_set.json','r', encoding=\"utf-8\"))\n",
    "frequency_bigram_set = json.load(open('../output/概率方法/frequency_bigram_set.json','r', encoding=\"utf-8\"))\n",
    "frequency_bigram_set2 = json.load(open('../output/概率方法/frequency_bigram_set2.json','r', encoding=\"utf-8\"))\n",
    "t_set = json.load(open('../output/t-test假设检验方法/t_set.json','r', encoding=\"utf-8\"))\n",
    "t_set_sorted = sorted(t_set.items(), key = lambda kv:(kv[1], kv[0]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUnigramFrequency(frequency_unigram_set, word, tag_pattern = None):\n",
    "    if (not word == None) and (not tag_pattern == None):\n",
    "        try:\n",
    "            return frequency_unigram_set[f'{word}&{tag_pattern}']\n",
    "        except:\n",
    "            return 0\n",
    "    elif (not word == None) and (tag_pattern == None):\n",
    "        f = 0\n",
    "        for unigram in frequency_unigram_set:\n",
    "            word_pattern = bigram.split('&')\n",
    "            if word == word_pattern[0]:\n",
    "                f += frequency_unigram_set[unigram]\n",
    "        return f\n",
    "    elif (word == None) and (not tag_pattern == None):\n",
    "        f = 0\n",
    "        for bigram in frequency_unigram_set:\n",
    "            word_pattern = bigram.split('&')\n",
    "            if tag_pattern == word_pattern[1]:\n",
    "                f += frequency_unigram_set[bigram]\n",
    "        return f\n",
    "    elif (word == None) and (tag_pattern == None):\n",
    "        return 0\n",
    "\n",
    "def getBigramFrequency(frequency_bigram_set2, word0, word1, tag_pattern0 = None, tag_pattern1 = None):\n",
    "    if (word0 == None) and (tag_pattern0 == None) and (word1 == None) and (tag_pattern1 == None):\n",
    "        return 0\n",
    "    elif (not tag_pattern0 == None) and (not tag_pattern1 == None):\n",
    "        try:\n",
    "            return frequency_bigram_set2[f'{word0}&{tag_pattern0}&{word1}&{tag_pattern1}']\n",
    "        except:\n",
    "            return 0\n",
    "    elif (not tag_pattern0 == None) and (tag_pattern1 == None):\n",
    "        f = 0\n",
    "        for bigram in frequency_bigram_set2:\n",
    "            word_pattern = bigram.split('&')\n",
    "            if word0 == word_pattern[0] and tag_pattern0 == word_pattern[1] and word1 == word_pattern[2]:\n",
    "                f += frequency_bigram_set2[bigram]\n",
    "        return f\n",
    "    elif (tag_pattern0 == None) and (not tag_pattern1 == None):\n",
    "        f = 0\n",
    "        for bigram in frequency_bigram_set2:\n",
    "            word_pattern = bigram.split('&')\n",
    "            if word0 == word_pattern[0] and word1 == word_pattern[2] and tag_pattern1 == word_pattern[3]:\n",
    "                f += frequency_bigram_set2[bigram]\n",
    "        return f\n",
    "    elif (tag_pattern0 == None) and (tag_pattern1 == None):\n",
    "        f = 0\n",
    "        for bigram in frequency_bigram_set2:\n",
    "            word_pattern = bigram.split('&')\n",
    "            if word0 == word_pattern[0] and word1 == word_pattern[2]:\n",
    "                f += frequency_bigram_set2[bigram]\n",
    "        return f\n",
    "\n",
    "def calT(frequency_bigram_set2, word01, word02, word1, tag_pattern01 = None, tag_pattern02 = None, tag_pattern1 = None):\n",
    "    f1 = getBigramFrequency(frequency_bigram_set2, word01, word1, tag_pattern01, tag_pattern1)\n",
    "    f2 = getBigramFrequency(frequency_bigram_set2, word02, word1, tag_pattern02, tag_pattern1)\n",
    "    t = (f1 - f2) / math.sqrt(f1 + f2)\n",
    "    return t\n",
    "\n",
    "def tOfDifferences(t_set_sorted, frequency_bigram_set, frequency_bigram_set2, word01, word02, tag_pattern01, tag_pattern02, K = 10):\n",
    "    print(f'===================== t of Differences: ({word01}-{tag_pattern01} {word02}-{tag_pattern02}) =====================')\n",
    "    if word01 == None and word02 == None and tag_pattern01 == None and tag_pattern02 == None:\n",
    "        return 0\n",
    "\n",
    "    # 统计出现过的后面的词\n",
    "    word1_list = []\n",
    "    for word_pattern in frequency_bigram_set[f'{word01}&{tag_pattern01}']:\n",
    "        word1_list.append(word_pattern)\n",
    "    for word_pattern in frequency_bigram_set[f'{word02}&{tag_pattern02}']:\n",
    "        word1_list.append(word_pattern)\n",
    "    word1_list = list(set(word1_list))      # 去重\n",
    "\n",
    "    t_result = {}\n",
    "    for word_pattern in word1_list:\n",
    "        word1 = word_pattern.split('&')[0]\n",
    "        pattern1 = word_pattern.split('&')[1]\n",
    "        t_result[word_pattern] = calT(frequency_bigram_set2, word01, word02, word1, tag_pattern01, tag_pattern02, tag_pattern1 = pattern1)\n",
    "\n",
    "\n",
    "    t_result = sorted(t_result.items(), key = lambda kv:(kv[1], kv[0]), reverse=True)\n",
    "    for i in range(1, K + 1):\n",
    "        bigram = t_result[i]\n",
    "        word_pattern = bigram[0].split('&')\n",
    "        word1 = word_pattern[0]\n",
    "        pattern1 = word_pattern[1]\n",
    "        f0 = getUnigramFrequency(frequency_unigram_set, word = word1, tag_pattern = pattern1)\n",
    "        f1 = getBigramFrequency(frequency_bigram_set2, word01, word1, tag_pattern01, pattern1)\n",
    "        f2 = getBigramFrequency(frequency_bigram_set2, word02, word1, tag_pattern02, pattern1)\n",
    "        print(f'{i}: {bigram}, c({word1}-{pattern1}) = {f0}, c({word01}-{tag_pattern01}-{word1}-{pattern1}) = {f1}, c({word02}-{tag_pattern02}-{word1}-{pattern1}) = {f2}')\n",
    "    print('-------------------------------------------')\n",
    "    for i in range(-1, -K-1, -1):\n",
    "        bigram = t_result[i]\n",
    "        word_pattern = bigram[0].split('&')\n",
    "        word1 = word_pattern[0]\n",
    "        pattern1 = word_pattern[1]\n",
    "        f0 = getUnigramFrequency(frequency_unigram_set, word = word1, tag_pattern = pattern1)\n",
    "        f1 = getBigramFrequency(frequency_bigram_set2, word01, word1, tag_pattern01, pattern1)\n",
    "        f2 = getBigramFrequency(frequency_bigram_set2, word02, word1, tag_pattern02, pattern1)\n",
    "        print(f'{-i}: ({bigram[0]}, {-bigram[1]}), c({word1}-{pattern1}) = {f0}, c({word01}-{tag_pattern01}-{word1}-{pattern1}) = {f1}, c({word02}-{tag_pattern02}-{word1}-{pattern1}) = {f2}')\n",
    "    \n",
    "\n",
    "def tByTagPattern(t_set_sorted, frequency_unigram_set, frequency_bigram_set2, tag_pattern, K = 10):\n",
    "    print(f'===================== t By Tag Pattern: ({tag_pattern[0]} {tag_pattern[1]}) =====================')\n",
    "    count = 0\n",
    "    for bigram in t_set_sorted:\n",
    "        if count >= K:\n",
    "            break\n",
    "        word_pattern = bigram[0].split('&')\n",
    "        word0 = word_pattern[0]\n",
    "        pattern0 = word_pattern[1]\n",
    "        word1 = word_pattern[2]\n",
    "        pattern1 = word_pattern[3]\n",
    "        if (not tag_pattern[0] == None) and (not tag_pattern[1] == None) and pattern0 == tag_pattern[0] and pattern1 == tag_pattern[1]:\n",
    "            count += 1\n",
    "            f0 = getUnigramFrequency(frequency_unigram_set, word = word0, tag_pattern = pattern0)\n",
    "            f1 = getUnigramFrequency(frequency_unigram_set, word = word1, tag_pattern = pattern1)\n",
    "            f2 = getBigramFrequency(frequency_bigram_set2, word0, word1, pattern0, pattern1)\n",
    "            print(f'{count}: {bigram}, c({word0}-{pattern0}) = {f0}, c({word1}-{pattern1}) = {f1}, c({bigram[0]}) = {f2}')\n",
    "        elif (not tag_pattern[0] == None) and (tag_pattern[1] == None) and pattern0 == tag_pattern[0]:\n",
    "            count += 1\n",
    "            f0 = getUnigramFrequency(frequency_unigram_set, word = word0, tag_pattern = pattern0)\n",
    "            f1 = getUnigramFrequency(frequency_unigram_set, word = word1, tag_pattern = pattern1)\n",
    "            f2 = getBigramFrequency(frequency_bigram_set2, word0, word1, pattern0, pattern1)\n",
    "            print(f'{count}: {bigram}, c({word0}-{pattern0}) = {f0}, c({word1}-{pattern1}) = {f1}, c({bigram[0]}) = {f2}')\n",
    "        elif (tag_pattern[0] == None) and (not tag_pattern[1] == None) and pattern1 == tag_pattern[1]:\n",
    "            count += 1\n",
    "            f0 = getUnigramFrequency(frequency_unigram_set, word = word0, tag_pattern = pattern0)\n",
    "            f1 = getUnigramFrequency(frequency_unigram_set, word = word1, tag_pattern = pattern1)\n",
    "            f2 = getBigramFrequency(frequency_bigram_set2, word0, word1, pattern0, pattern1)\n",
    "            print(f'{count}: {bigram}, c({word0}-{pattern0}) = {f0}, c({word1}-{pattern1}) = {f1}, c({bigram[0]}) = {f2}')\n",
    "        elif (tag_pattern[0] == None) and (tag_pattern[1] == None):\n",
    "            count += 1\n",
    "            f0 = getUnigramFrequency(frequency_unigram_set, word = word0, tag_pattern = pattern0)\n",
    "            f1 = getUnigramFrequency(frequency_unigram_set, word = word1, tag_pattern = pattern1)\n",
    "            f2 = getBigramFrequency(frequency_bigram_set2, word0, word1, pattern0, pattern1)\n",
    "            print(f'{count}: {bigram}, c({word0}-{pattern0}) = {f0}, c({word1}-{pattern1}) = {f1}, c({bigram[0]}) = {f2}')\n",
    "\n",
    "def tByWord0(t_set_sorted, frequency_unigram_set, frequency_bigram_set2, word0, tag_pattern0, tag_pattern1 = None, K = 10):\n",
    "    print(f'===================== t By Word0: ({word0}&{tag_pattern0} {tag_pattern1}) =====================')\n",
    "    if word0 == None:\n",
    "        return 0\n",
    "\n",
    "    count = 0\n",
    "    for bigram in t_set_sorted:\n",
    "        if count >= K:\n",
    "            break\n",
    "        word_pattern = bigram[0].split('&')\n",
    "        pattern0 = word_pattern[1]\n",
    "        word1 = word_pattern[2]\n",
    "        pattern1 = word_pattern[3]\n",
    "        if (not tag_pattern[0] == None) and (not tag_pattern[1] == None) and pattern0 == tag_pattern[0] and pattern1 == tag_pattern[1] and word0 == word_pattern[0]:\n",
    "            count += 1\n",
    "            f0 = getUnigramFrequency(frequency_unigram_set, word = word0, tag_pattern = pattern0)\n",
    "            f1 = getUnigramFrequency(frequency_unigram_set, word = word1, tag_pattern = pattern1)\n",
    "            f2 = getBigramFrequency(frequency_bigram_set2, word0, word1, pattern0, pattern1)\n",
    "            print(f'{count}: {bigram}, c({word0}-{pattern0}) = {f0}, c({word1}-{pattern1}) = {f1}, c({bigram[0]}) = {f2}')\n",
    "        elif (not tag_pattern[0] == None) and (tag_pattern[1] == None) and pattern0 == tag_pattern[0] and word0 == word_pattern[0]:\n",
    "            count += 1\n",
    "            f0 = getUnigramFrequency(frequency_unigram_set, word = word0, tag_pattern = pattern0)\n",
    "            f1 = getUnigramFrequency(frequency_unigram_set, word = word1, tag_pattern = pattern1)\n",
    "            f2 = getBigramFrequency(frequency_bigram_set2, word0, word1, pattern0, pattern1)\n",
    "            print(f'{count}: {bigram}, c({word0}-{pattern0}) = {f0}, c({word1}-{pattern1}) = {f1}, c({bigram[0]}) = {f2}')\n",
    "        elif (tag_pattern[0] == None) and (not tag_pattern[1] == None) and pattern1 == tag_pattern[1] and word0 == word_pattern[0]:\n",
    "            count += 1\n",
    "            f0 = getUnigramFrequency(frequency_unigram_set, word = word0, tag_pattern = pattern0)\n",
    "            f1 = getUnigramFrequency(frequency_unigram_set, word = word1, tag_pattern = pattern1)\n",
    "            f2 = getBigramFrequency(frequency_bigram_set2, word0, word1, pattern0, pattern1)\n",
    "            print(f'{count}: {bigram}, c({word0}-{pattern0}) = {f0}, c({word1}-{pattern1}) = {f1}, c({bigram[0]}) = {f2}')\n",
    "        elif (tag_pattern[0] == None) and (tag_pattern[1] == None) and word0 == word_pattern[0]:\n",
    "            count += 1\n",
    "            f0 = getUnigramFrequency(frequency_unigram_set, word = word0, tag_pattern = pattern0)\n",
    "            f1 = getUnigramFrequency(frequency_unigram_set, word = word1, tag_pattern = pattern1)\n",
    "            f2 = getBigramFrequency(frequency_bigram_set2, word0, word1, pattern0, pattern1)\n",
    "            print(f'{count}: {bigram}, c({word0}-{pattern0}) = {f0}, c({word1}-{pattern1}) = {f1}, c({bigram[0]}) = {f2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "===================== t By Tag Pattern: (VERB NOUN) =====================\n",
      "1: ('附&VERB&图片&NOUN', 17.105212930501057), c(附-VERB) = 295, c(图片-NOUN) = 628, c(附&VERB&图片&NOUN) = 293\n",
      "2: ('令&VERB&人&NOUN', 11.926201538324738), c(令-VERB) = 245, c(人-NOUN) = 3252, c(令&VERB&人&NOUN) = 144\n",
      "3: ('反&VERB&腐败&NOUN', 11.784244751284598), c(反-VERB) = 286, c(腐败-NOUN) = 207, c(反&VERB&腐败&NOUN) = 139\n",
      "4: ('高举&VERB&邓小平理论&NOUN', 9.10737189709686), c(高举-VERB) = 105, c(邓小平理论-NOUN) = 239, c(高举&VERB&邓小平理论&NOUN) = 83\n",
      "5: ('为&VERB&核心&NOUN', 9.060104016019359), c(为-VERB) = 2845, c(核心-NOUN) = 145, c(为&VERB&核心&NOUN) = 83\n",
      "6: ('跨&VERB&世纪&NOUN', 8.823086804689563), c(跨-VERB) = 126, c(世纪-NOUN) = 547, c(跨&VERB&世纪&NOUN) = 78\n",
      "7: ('让&VERB&人&NOUN', 8.270284507909636), c(让-VERB) = 647, c(人-NOUN) = 3252, c(让&VERB&人&NOUN) = 73\n",
      "8: ('有&VERB&可能&NOUN', 8.241930650705863), c(有-VERB) = 5494, c(可能-NOUN) = 88, c(有&VERB&可能&NOUN) = 69\n",
      "9: ('是&VERB&我国&NOUN', 8.219718808816781), c(是-VERB) = 10347, c(我国-NOUN) = 1194, c(是&VERB&我国&NOUN) = 93\n",
      "10: ('送&VERB&温暖&NOUN', 7.803176680027382), c(送-VERB) = 497, c(温暖-NOUN) = 100, c(送&VERB&温暖&NOUN) = 61\n",
      "===================== t By Tag Pattern: (None None) =====================\n",
      "1: ('一&NUM&种&NOUN', 24.64070434956733), c(一-NUM) = 8624, c(种-NOUN) = 990, c(一&NUM&种&NOUN) = 626\n",
      "2: ('这&PRON&一&NUM', 24.131314565610214), c(这-PRON) = 3353, c(一-NUM) = 8624, c(这&PRON&一&NUM) = 645\n",
      "3: ('这&PRON&是&VERB', 22.570383614905815), c(这-PRON) = 3353, c(是-VERB) = 10347, c(这&PRON&是&VERB) = 584\n",
      "4: ('两&NUM&国&NOUN', 22.376429468968823), c(两-NUM) = 2297, c(国-NOUN) = 843, c(两&NUM&国&NOUN) = 505\n",
      "5: ('新&ADJ&的&PART', 22.277431063758527), c(新-ADJ) = 2179, c(的-PART) = 62193, c(新&ADJ&的&PART) = 768\n",
      "6: ('一&NUM&年&NOUN', 21.566043917524624), c(一-NUM) = 8624, c(年-NOUN) = 4277, c(一&NUM&年&NOUN) = 544\n",
      "7: ('就&ADV&是&VERB', 21.555263274163963), c(就-ADV) = 2475, c(是-VERB) = 10347, c(就&ADV&是&VERB) = 520\n",
      "8: ('本报&PRON&讯&ADP', 21.48774649075544), c(本报-PRON) = 1467, c(讯-ADP) = 699, c(本报&PRON&讯&ADP) = 464\n",
      "9: ('江&PROPN&泽民&PROPN', 21.10468366945642), c(江-PROPN) = 591, c(泽民-PROPN) = 451, c(江&PROPN&泽民&PROPN) = 446\n",
      "10: ('北京&PROPN&1月&NOUN', 21.055278174865496), c(北京-PROPN) = 1438, c(1月-NOUN) = 1781, c(北京&PROPN&1月&NOUN) = 449\n",
      "===================== t By Word0: (高举&VERB None) =====================\n",
      "1: ('高举&VERB&邓小平理论&NOUN', 9.10737189709686), c(高举-VERB) = 105, c(邓小平理论-NOUN) = 239, c(高举&VERB&邓小平理论&NOUN) = 83\n",
      "2: ('高举&VERB&旗帜&NOUN', 1.992005490841188), c(高举-VERB) = 105, c(旗帜-NOUN) = 137, c(高举&VERB&旗帜&NOUN) = 4\n",
      "3: ('高举&VERB&毛泽东思想&NOUN', 1.7302988888479012), c(高举-VERB) = 105, c(毛泽东思想-NOUN) = 26, c(高举&VERB&毛泽东思想&NOUN) = 3\n",
      "4: ('高举&VERB&胳膊&NOUN', 0.9989496265338786), c(高举-VERB) = 105, c(胳膊-NOUN) = 9, c(高举&VERB&胳膊&NOUN) = 1\n",
      "5: ('高举&VERB&爱国主义&NOUN', 0.9957985061355149), c(高举-VERB) = 105, c(爱国主义-NOUN) = 36, c(高举&VERB&爱国主义&NOUN) = 1\n",
      "6: ('高举&VERB&政治&NOUN', 0.9311421838876044), c(高举-VERB) = 105, c(政治-NOUN) = 590, c(高举&VERB&政治&NOUN) = 1\n",
      "7: ('高举&VERB&社会主义&NOUN', 0.9162035390361019), c(高举-VERB) = 105, c(社会主义-NOUN) = 718, c(高举&VERB&社会主义&NOUN) = 1\n",
      "===================== t By Word0: (高举&VERB NOUN) =====================\n",
      "1: ('高举&VERB&邓小平理论&NOUN', 9.10737189709686), c(高举-VERB) = 105, c(邓小平理论-NOUN) = 239, c(高举&VERB&邓小平理论&NOUN) = 83\n",
      "2: ('高举&VERB&旗帜&NOUN', 1.992005490841188), c(高举-VERB) = 105, c(旗帜-NOUN) = 137, c(高举&VERB&旗帜&NOUN) = 4\n",
      "3: ('高举&VERB&毛泽东思想&NOUN', 1.7302988888479012), c(高举-VERB) = 105, c(毛泽东思想-NOUN) = 26, c(高举&VERB&毛泽东思想&NOUN) = 3\n",
      "4: ('高举&VERB&胳膊&NOUN', 0.9989496265338786), c(高举-VERB) = 105, c(胳膊-NOUN) = 9, c(高举&VERB&胳膊&NOUN) = 1\n",
      "5: ('高举&VERB&爱国主义&NOUN', 0.9957985061355149), c(高举-VERB) = 105, c(爱国主义-NOUN) = 36, c(高举&VERB&爱国主义&NOUN) = 1\n",
      "6: ('高举&VERB&政治&NOUN', 0.9311421838876044), c(高举-VERB) = 105, c(政治-NOUN) = 590, c(高举&VERB&政治&NOUN) = 1\n",
      "7: ('高举&VERB&社会主义&NOUN', 0.9162035390361019), c(高举-VERB) = 105, c(社会主义-NOUN) = 718, c(高举&VERB&社会主义&NOUN) = 1\n",
      "===================== t of Differences: (美好-ADJ 热情-ADJ) =====================\n",
      "1: ('未来&NOUN', 2.23606797749979), c(未来-NOUN) = 200, c(美好-ADJ-未来-NOUN) = 5, c(热情-ADJ-未来-NOUN) = 0\n",
      "2: ('祝福&NOUN', 1.7320508075688774), c(祝福-NOUN) = 24, c(美好-ADJ-祝福-NOUN) = 3, c(热情-ADJ-祝福-NOUN) = 0\n",
      "3: ('形象&NOUN', 1.7320508075688774), c(形象-NOUN) = 161, c(美好-ADJ-形象-NOUN) = 3, c(热情-ADJ-形象-NOUN) = 0\n",
      "4: ('祝愿&NOUN', 1.414213562373095), c(祝愿-NOUN) = 27, c(美好-ADJ-祝愿-NOUN) = 2, c(热情-ADJ-祝愿-NOUN) = 0\n",
      "5: ('明天&NOUN', 1.414213562373095), c(明天-NOUN) = 103, c(美好-ADJ-明天-NOUN) = 2, c(热情-ADJ-明天-NOUN) = 0\n",
      "6: ('故事&NOUN', 1.414213562373095), c(故事-NOUN) = 169, c(美好-ADJ-故事-NOUN) = 2, c(热情-ADJ-故事-NOUN) = 0\n",
      "7: ('前景&NOUN', 1.414213562373095), c(前景-NOUN) = 106, c(美好-ADJ-前景-NOUN) = 2, c(热情-ADJ-前景-NOUN) = 0\n",
      "8: ('人生&NOUN', 1.414213562373095), c(人生-NOUN) = 89, c(美好-ADJ-人生-NOUN) = 2, c(热情-ADJ-人生-NOUN) = 0\n",
      "9: ('魅力&NOUN', 1.0), c(魅力-NOUN) = 59, c(美好-ADJ-魅力-NOUN) = 1, c(热情-ADJ-魅力-NOUN) = 0\n",
      "10: ('青春&NOUN', 1.0), c(青春-NOUN) = 30, c(美好-ADJ-青春-NOUN) = 1, c(热情-ADJ-青春-NOUN) = 0\n",
      "-------------------------------------------\n",
      "1: (地&PART, 3.162277660168379), c(地-PART) = 2303, c(美好-ADJ-地-PART) = 0, c(热情-ADJ-地-PART) = 10\n",
      "2: (接待&NOUN, 2.0), c(接待-NOUN) = 19, c(美好-ADJ-接待-NOUN) = 0, c(热情-ADJ-接待-NOUN) = 4\n",
      "3: (大方&ADJ, 1.414213562373095), c(大方-ADJ) = 7, c(美好-ADJ-大方-ADJ) = 0, c(热情-ADJ-大方-ADJ) = 2\n",
      "4: (为&ADP, 1.0), c(为-ADP) = 2644, c(美好-ADJ-为-ADP) = 0, c(热情-ADJ-为-ADP) = 1\n",
      "5: (也&ADV, 1.0), c(也-ADV) = 3223, c(美好-ADJ-也-ADV) = 0, c(热情-ADJ-也-ADV) = 1\n",
      "6: (似&ADV, 1.0), c(似-ADV) = 18, c(美好-ADJ-似-ADV) = 0, c(热情-ADJ-似-ADV) = 1\n",
      "7: (关注&NOUN, 1.0), c(关注-NOUN) = 57, c(美好-ADJ-关注-NOUN) = 0, c(热情-ADJ-关注-NOUN) = 1\n",
      "8: (勉励&NOUN, 1.0), c(勉励-NOUN) = 1, c(美好-ADJ-勉励-NOUN) = 0, c(热情-ADJ-勉励-NOUN) = 1\n",
      "9: (友好&ADJ, 1.0), c(友好-ADJ) = 196, c(美好-ADJ-友好-ADJ) = 0, c(热情-ADJ-友好-ADJ) = 1\n",
      "10: (周到&ADJ, 1.0), c(周到-ADJ) = 3, c(美好-ADJ-周到-ADJ) = 0, c(热情-ADJ-周到-ADJ) = 1\n"
     ]
    }
   ],
   "source": [
    "tag_pattern = ['VERB', 'NOUN']\n",
    "tByTagPattern(t_set_sorted, frequency_unigram_set, frequency_bigram_set2, tag_pattern)\n",
    "tByTagPattern(t_set_sorted, frequency_unigram_set, frequency_bigram_set2, [None, None])\n",
    "\n",
    "tByWord0(t_set_sorted, frequency_unigram_set, frequency_bigram_set2, '高举', 'VERB', tag_pattern1 = None)\n",
    "tByWord0(t_set_sorted, frequency_unigram_set, frequency_bigram_set2, '高举', 'VERB', tag_pattern1 = 'NOUN')\n",
    "\n",
    "tOfDifferences(t_set_sorted, frequency_bigram_set, frequency_bigram_set2, word01 = '美好', word02 = '热情', tag_pattern01 = 'ADJ', tag_pattern02 = 'ADJ', K = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}